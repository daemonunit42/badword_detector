<h1 align="center">ğŸ›¡ï¸ Conversation Moderation System</h1>

<p align="center">
  <b>Real-time AI moderation that understands conversations, enforces rules, and keeps communities safe.</b>
</p>

<hr>

<h2>âœ¨ Overview</h2>
<p>
An intelligent, real-time moderation engine designed to monitor user conversations and enforce community safety rules automatically.
The system analyzes messages as a live conversation unfolds, detects abusive or offensive content using AI,
and applies progressive warnings leading up to a ban.
</p>

<hr>

<h2>ğŸŒŸ Key Highlights</h2>
<ul>
  <li>ğŸ¤– <b>AI-Driven Moderation</b> â€” Detects toxic, hateful, abusive, and inappropriate language with high accuracy</li>
  <li>ğŸ’¬ <b>Live Conversation Mode</b> â€” Feels like a real chat between a user and the system</li>
  <li>âš ï¸ <b>Progressive Warning System</b> â€” Automatic escalation from warning to ban</li>
  <li>ğŸ”’ <b>Persistent User Tracking</b> â€” Warning history is saved across sessions</li>
  <li>ğŸŒ <b>LLM-Powered Intelligence</b> â€” Uses OpenRouter with Mistral 7B Instruct</li>
  <li>ğŸ§  <b>Fail-Safe Parsing</b> â€” Gracefully handles malformed AI responses</li>
</ul>

<hr>

<h2>ğŸš€ How It Works</h2>
<ol>
  <li>User joins the system with a unique username</li>
  <li>Each message is analyzed instantly by the AI moderation model</li>
  <li>Clean messages are allowed without interruption</li>
  <li>Offensive messages trigger escalating warnings</li>
  <li>After three violations, the user is automatically banned</li>
</ol>

<p>
All moderation decisions persist across sessions for consistent enforcement.
</p>

<hr>

<h2>ğŸ§ª Use Cases</h2>
<ul>
  <li>Chat applications & community forums</li>
  <li>Discord / Telegram moderation bots</li>
  <li>Online multiplayer game chats</li>
  <li>Educational platforms</li>
  <li>AI safety and research projects</li>
</ul>

<hr>

<h2>âš™ï¸ Tech Stack</h2>
<ul>
  <li><b>Language:</b> Python 3.11+</li>
  <li><b>AI API:</b> OpenRouter</li>
  <li><b>Model:</b> Mistral 7B Instruct</li>
  <li><b>Config:</b> dotenv (.env)</li>
  <li><b>Storage:</b> JSON-based persistence</li>
</ul>

<hr>

<h2>ğŸ§  Philosophy</h2>
<blockquote>
  â€œModeration should be intelligent, fair, and automatic â€” not reactive.â€
</blockquote>

<p>
This project focuses on <b>preventive AI moderation</b>, creating safer digital spaces without constant human oversight.
</p>

<hr>

<h2>ğŸ“Œ Project Status</h2>
<p>
ğŸš§ <b>Actively evolving</b><br>
Upcoming upgrades include:
</p>

<ul>
  <li>Full AI conversational responses</li>
  <li>Sentiment scoring & analytics</li>
  <li>Admin dashboard</li>
  <li>Bot & platform integrations</li>
</ul>

<hr>

<p align="center">
  <b>Built for safety. Powered by AI. Designed for real conversations.</b>
</p>
